# getinterviewed

1. **PySpark:**
   - *Topics covered:* Spark Architecture, PySpark hands-on experience, optimization techniques, and challenges.
   - *Scenario-based questions:*
     - "Optimizing a PySpark job processing a massive dataset."
     - "Handling errors in transformations due to data inconsistencies."

2. **Python:**
   - *Topics covered:* Differences between list, tuple, dictionary, and set; Python generators and decorators.
   - *Scenario-based questions:*
     - "Designing a data processing script using lists, tuples, dictionaries, sets, generators, and decorators."
     - "Creating a Python script for analyzing a large dataset efficiently."

3. **SQL:**
   - *Topics covered:* SQL coding skills, involving joins, window functions, lead/lag.
   - *Scenario-based questions:*
     - "Designing a SQL query for identifying and eliminating duplicate records."
     - "Creating a report showing monthly revenue for each product using window functions."

4. **ETL Concepts:**
   - *Topics covered:* Slowly changing dimensions, data lake, delta lake, data warehouse, normalization, denormalization, data cleansing, metadata management, change data capture (CDC).
   - *Scenario-based questions:*
     - "Implementing a slowly changing dimension strategy for historical data."
     - "Designing an ETL process for rapidly changing datasets."

5. **Cloud Services:**
   - *Topics covered:* Cloud-agnostic concepts, adaptability, efficiency, and data transfer.
   - *Scenario-based questions:*
     - "Designing a scalable and cost-effective data storage solution in a cloud environment."
     - "Ensuring efficient ETL processes while maintaining data quality in a project with diverse data sources stored in a data lake."
